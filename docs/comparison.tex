\documentclass[]{scrartcl}

\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}

%opening
\title{Comparison of Kubernetes with the proposed orchestration approach}
\author{Florian Hofer}

\begin{document}

\maketitle

\section{Kubernetes}

Kubernetes is a well-known container management platform developed by Google. It is able manage multiple containers also distributed on various hosts. The advantage is for sure the offered centralized control portal. 

In Kubernetes the resource management is performed previous to container deployment. Similar to docker-compose, the resources such as memory and CPU-limit can be specified in a JSON based configuration file. The configuration file describes the resource requests and upper limits for a set of containers, also called a Pod. 
For these settings there are three combinations, fitting into three Quality of Service classes\footnote{https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md}:
% ADd information about QoS management of extras, and overshoots, margin can be set by observaton.
\begin{itemize}
	\item Best-effort: limits and requests are not set, thus all the pods and containers are run in a best effort manner. These are also the lowest priority and the first pods to be killed when a system runs low of memory.
	\item Burst: for some containers, requests and optionally limits are set greater than 0 and not equal for one or more resources. Here a minimum of resources are guaranteed, which can top up until they reach the configuration or system limit. Once threre are no more best-effort pods available, these are the most likely pods to be killed in system memory distress.
	\item Guaranteed: limits and optionally requests are set greater than 0 and equal for all resources and containers, the pod is said to be guaranteed. These pods run top priority and are not to be killed until either they exceed their memory limits or there are no lower priority pods to be depleted. 
\end{itemize}
In all cases, if CPU-time can not be met, the process will be throttled down and not killed.

The required resources of a Pod are actually the request amount for the run of the whole container collection, thus the sum of resources. All resource requests of the pod must be fulfilled for the containers to be deployed.


The information about Kubernetes has been taken from:
\href{https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/}{Kubernetes Documentation}.


\section{Orchestration engine}

The orchestration engine, different from Kubernetes, is a management tool that works directly on the scheduling level. The application code will run in a container like all the other real-time applications. This will help to augment the flexibility of the solution. A downside of the solution might be that the engine can operate just on local level.

In the previous example, the configuration of the resources has been done by limits. The orchestration engine instead will work on task data and their real-time properties. 
Thus, the input parameters are start-time, runtime, period and eventually deadline in addition to the regular task priority.
All the tasks will still be threatened separately, giving the tool little more flexibility in local deployment of CPU-time.


\section{Comparison}

Table \ref{tab:approach} gives a quick overview of the technologies in comparison.
The advantage of Kubernetes is the centralized management of containers. The limits for each container can be set in a group configuration and then downloaded to the hosts. The disadvantage here is that the limits must be set big enough to manage eventual overshoots. Thus, the CPU-time must be set to the maximum expected and/or measures or an overload caused by a overshoot will never be recovered again.
Kubernetes can not manage such situations as it is not directly acting on the scheduler but only on the offline configuration.

The orchestration engine on the other hand, knows the tasks to be run their properties and deadlines. In the dynamic version it will also be able to shift tasks to other computation units when needed. The advantage here is that a overload of resouces might be avoided.
The compelsity of this approach is for sure higher. While kubernetes might simply set control group limits on the container tasks, the orchestrator has to continuously monitor the exectuon of the tasks.
On the other hand, this brings the advantage that the application always knows status and limits of the system. Tbus, it is possible to manage resources in a drastically more efficient manner, having task deadlines as upper bound and task runtimes als lower. This permits to achieve, e.g. in the table, more then 3x the tasks running on the same amount of cores.

\begin{table}[ht]
	\centering
	\begin{tabular}{l c c c}
		Property & Kubernetes & \multicolumn{2}{c}{Orchestrator} \\
		& & static & dynamic \\
		\toprule
		Action range & Cluster & Local & Local \\
		Configuration & Json & Task & Task \\
		\midrule
		Controls & CPU, memory & CPU & CPU \\
		Groups & Pods* & N/A & N/A\\
		\midrule
		Upper limits & expected max & Config & Deadline \\
		Overshoots & Critical & Critical & Managed \\
		Real-time & not eval & considered & evaluated \\
		\midrule
		\shortstack{Tasks per CPU w/ 10\% run,\\
		 dl 20\% + 300\% overshoots} & 3 & 3 & 5-10\\		
		\bottomrule
	\end{tabular}
	\caption{Comparison table of the different management approaches}
	\label{tab:approach}
\end{table}

But the advantages are not finished here: 
The table clearly shows that the two approaches are different and not concurrent. If CPU limitation and affinity is not applied, the two solutions together can exploit advantages on both sides. While it might be true that also the orchestrator could, with the help of Cgrpups. add also memory management including numa node management, the cooperation of the remote management tool and the integration of the orchestratior with the kubelet agent might tbe easiest and most profitable solution. 

\section{Conclusions}

The two solutions are different in kind. While a static approach would get very similar results, the dynamic orchestrator could reach higher resource economy by allocating a higher number of tasks on the same resources.
The feasibility of a combined approach and the actual performance of the orchestrator are still to be determined, anyway, the data seems promising.


\end{document}
