\documentclass[]{scrartcl}
\usepackage{hyperref}

%opening
\title{Orchestrating real-time containers:\\ on the possibilities of schedule manipulation}
\author{Florian Hofer}

\begin{document}

\maketitle

\begin{abstract}
In this document, an exploratory step by step investigation on process management and scheduling techniques are discussed.
%TODO: abstract? //  After some inituial 
\end{abstract}

\section{Introduction}


%What is the state - Background, historical, terms and definitions
Emerging technologies such as the Internet of Things and Cloud Computing are re-shaping the structure and control of industrial processes radically. 
The extent of these innovations, which allow the creation of highly flexible production systems, is so wide that today we talk about a fourth industrial revolution.
Key enabling technologies such as distributed sensing, big-data analysis and cloud storage are taking the center stage in developing new industrial control systems.

The control of industrial processes, however, has not changed much over the last few decades, and there are reasons for it.
For instance, typical control applications found in industrial processes have to respond to changes in the physical world within predefined time limits.
Moving the execution of control tasks from devices physically co-located with the controlled process to cloud or fog computing platforms requires dealing with network delays that are difficult to predict.
Moreover, while bare-metal solutions lend the control design full authority over the environment in which its software will run, it is not straightforward to determine under what conditions the software can be executed on cloud computing platforms due to resource virtualization properties.
Yet, we believe that the principles of Industry 4.0 present a unique opportunity to explore complementing traditional automation components by a novel control architecture \cite{Tascietal2018}.

We believe that modern virtualization techniques such as application containerization \cite{Mogaetal2016,Tascietal2018,GoldschmidtHauck-Stattelmann2016} are key for adequate utilization of cloud computing resources in industrial control systems.
The use of containerized control applications would yield the same advantages that traditional containerized microservices present: light and easily distributable control applications would be able to, for instance, run on any system and at the same time, be easily maintained and updated. 
Thus, enhanced scalability, portability, updatability and availability can be achieved \cite{Fazioetal2016}.
%New -> Industry 4.0 relatedness..
Beyond the migration and resource savings, parallel operation of containers on devices such as PLCs and, in small amounts, on sensing and actuating field devices, is possible. 
This will increase reliability and robustness, while enabling further exploitation of Self-* properties including Self-awareness and Self-compare.
% same container on multiple devices = redundancy and reliability
% Ease maintenance, one system still up -> changes etc see Goldschmidtetal2018

% what do we do about it
In this paper, we explore the feasibility of managing real-time control applications running on a shared resource environment.
The contributions of this paper are: 
\begin{itemize}
	\item Evaluation of access and control techniques to vary a container's run parameters and constraints, including scheduling information;
	
	\item Exploration of implementation techniques of a task, which takes charge of automating those settings and constraints, further called orchestrator;
	
	\item Evaluation of monitoring and implementation of a monitoring interface;
	
	\item Static scheduling of application containers as real-time tasks;

	\item Latency and determinism tests to confirm parameters and configurations enabling static and (quasi) dynamic container management;
		
	\item Demonstration of how, under specific conditions, the same containers can be managed dynamically.
\end{itemize}

%Setup of the paper
%TODO: repass the structure
The rest of this paper is structured as follows. Section~\ref{sec:relwork} analyzes related work, while Section~\ref{sec:bgnd} introduces the background motivating this analysis. 
We next discuss methodology and design of experiments and review containerization frameworks in Section~\ref{sec:contfram}, and compare candidate host operating systems to run the container engine in Section~\ref{sec:ostest}. 
Finally, we document the tests performed in Section~\ref{sec:virtsust} and conclude in Section~\ref{sec:conclusion}.

\section{Related work}
\label{sec:relwork}
%TODO: redo!

%Let's start with approaches containers for control applications
Containerizing control applications has been discussed in recent literature. 
Morga et al. \cite{Mogaetal2016}, for instance, presented the concept of containerization of full control applications as a means to decouple the hardware and software life-cycles of an industrial automation system.
Due to the performance overhead in hardware virtualization, the authors state that OS-level virtualization is a suitable technique to cope with automation system timing demands.
The authors propose two approaches to migrate a control application into containers on top of a patched real-time Linux-based operating system: 
\begin{itemize}
	\item A given system is decomposed into subsystems, where a set of sub-units performs a localized computation, which then is actuated through a global decision maker. 
	\item Devices are defined, where each component is an isolated standalone solution with a shared communication stack.
	Based on this, systems are further divided into modules, allowing a granular development and update strategy. 
\end{itemize}
The authors demonstrate the feasibility of real-time applications in conjunction with containerization, even though they express concern on the maturity of the technical solution presented.

In related work, Goldschmidt and Hauk-Stattelmann \cite{GoldschmidtHauck-Stattelmann2016} presented a similar solution.
They perform benchmark tests on modularized industrial Programmable Logic Controller (PLC) applications to analyze the impact of container-based virtualization on real-time constraints.
As there is no solution for legacy code migration of PLCs to this point, the migration to application containers could extend a system's lifetime beyond the physical device's limits.
Even though tests showed worst-case latencies of the order of 15ms on Intel-based hosts (this may prevent direct application), the authors argue that the container engines may be stripped down and optimized for real-time execution.
In a follow-up work of Goldschmidt et al. \cite{Goldschmidtetal2018}, a possible multi-purpose architecture has been detailed and the proposal tested in a real-world use case.
The results show worst case latencies in the range of 1ms for a Raspberry PI single board computer, making the solution viable for cycle times in the range of 100ms to 1s.
The authors state that topics like memory overhead, containers' restricted access and problems due to technology immaturity are still to be investigated.

Tasci et al. \cite{Tascietal2018} address architectural details not discussed in \cite{GoldschmidtHauck-Stattelmann2016} and \cite{Goldschmidtetal2018}, such as the definite run-time environment and how deterministic communication of containers and field devices may be achieved in a novel container-based architecture. 
They propose a Linux-based solution as host operating system, including both the single kernel preemption-focused PREEMPT-RT patch and the co-kernel oriented Xenomai. 
With the latter patch, this approach shows better predictability, although it suffers from security constraints. For this reason, they suggest limiting its application for safety-critical code execution. 
They analyze and discuss in detail inter-process messaging, focusing on the specific properties needed in real-time applications.
Finally, they implement an orchestration run-time managing intra-container communication and show that task times of $500\mu s$ are possible.

%What about containers in the cloud?
The three solutions discussed above share one common property: they were based on bare-metal configurations. 
The solutions took into consideration real-time constraints, but limited to execution on physical hardware.
Nonetheless, current trends in industry favor the flexibility of resource sharing through cloud computing.
Thus, there is reason to investigate whether real-time control applications may also be ran on a shared infrastructure, their capabilities and limitations.

In 2014, Garcia-Vallas et al. \cite{Garcia-Vallsetal2014} analyzed challenges for predictable and deterministic cloud computing.
Even though the focus of their paper is on soft real-time applications, certain aspects and limits can be applied to any real-time systems.
Merging cloud computing with real-time requirements is a challenging task; the authors state that the guest OS has only limited access to physical hardware and thus suffers from unpredictability of non-hierarchical scheduling, and thick stack communications. 

% From here on focuses too much on containers, less on scheduling
%While there exist real-time enabled hypervisors, such as the paravirtualized RT-Xen with direct access to hardware, the shared resources still suffer from latencies that may make real-time execution impossible.
%Felter et al. in \cite{Felteretal2015} focused on identifying the performance of instances based on hardware virtualization via Kernel-based Virtual Machines (KVMs) and container OS-virtualization using Docker. 
%The benchmarks confirm that Docker results in equal or better performance than KVMs in almost all cases.
%Arango et al. \cite{Arangoetal2017} analyzed three containerization techniques for use in cloud computing. 
%The paper compares LXC, Docker and Singularity, an engine developed by Lawrence Berkeley National Laboratory, to a bare-metal application. 
%In many aspects, the Singularity containers performed better, sometimes even better than the bare-metal implementation, but this is largely due to the blended approach of the engine; Singularity is an incomplete virtualization solution in that it virtualizes only to a minimal degree, granting access to I/O operations without context changes.
%Additional information: They say depending on app and configuration to select the proper os


%But there is noone investigating the combination
So far, we have seen that containerization techniques have been tested with early positive results in a variety of contexts.
However, a combination of containers executed on cloud resources and control application containerization has not yet been examined in the literature. 
In this paper, we assess the feasibility of such approaches.


\section{Context and problem}

With the rising needs of a more distributed system, the requirements for a running control tasks change as well.
Different from before, the new software architectures foresee a distributed deployment of single functionalities, requiring the nodes to work together all in sync for a production process to work properly. 
%As discussed previously, those systems incur in timing requirements, wic
%Hardrealtimecionstraints to insert here
The new setup also puts systems and architectures in front of new development requirements. Software modules are now to be exchanged and updates in a distributed manner as the functionality itself is not located in as single place anymore. 
Thus, requires for a change in controlling and management of these software modules, at the cost to increase maintainability and ease of use of such systems.

Lately the trend to implement the single software modules into containers, isolated threads running in parallel on shared software. This has the advantage of abstracting the software model from its host, making maintenance and redundancy quite easy to achieve % rerfenrec to paper redundancy migration
However, these containers are not made to run with hard real-time constraint by default. Therefore, some changes at the operating system level as well as some orchestration has to be performed in order to guarantee the execution of the software within defined deadlines.
The containers may be orchestrated statically, knowing the actual execution time and periods, and all tasks that are present, or dynamically, as the tasks enter and leave, new schedules are computed on demand.
However, if the maximum peak execution time of a task is not known, the schedule of containers is undecidable. 

The dynamic scheduling will therefore be done at best using the following considerations.
For simplicity, we suppose that the tasks are all independent. The tasks are considered to be black boxes, so we don't have access to the source code. 
Quasi static and similar approaches opt to improve schedulability at compile-time are therefore not applicable.
The tasks may exceed the deadline, but in low probability and contemporaneity
we have to consider to define those values in order to obtain boundaries and limits. Might also be experimental values obtained from the running containers in Siemens Business Unit Farm


Containers are run, started either by runc or docker-run, and initialized if configured with an init thread as process 1. 
The new container has a different pid space and userspace
separate mount points for volumes. Docker we can specify --pid=host to set to a shared user-space.

\subsection{POSIX Standard}

The IEEE Std 1003.1 defines the interface every compliant operating system must have. The standard also foresees, in addition to the main process management features, an optional X/Open System Interfaces XSI conformance.
The constants that define the presence and function of such interfaces might be found in the <unistd.h> header file. 
The values can be directly interrogated by verifying the constant as described in the standard.
XSI defines in particular three option groups: encryption, realtime (threads) and advanced realtime (threads). 

as verified, only a few of the advanced realtime features are available. 
The conditional compiler flags might be used in the sourcecode for a more detailed outputs. 

\subsection{Non standardized extensions}

Interestingly, the posix standard does not define other scheduling types than other, fifo and RR. 
There is no mentioning of deadline, iso, or batch. 
At the same time, the standard foresees a structure defining the scheduler's parameters, but it contains only one parameter, the absolute scheduling priority.

This might be taken into consideration when trying to run the orchestrator in a non Linux environment.

%TODO: add subsection additional for LINUX, ie pidof??

\section{Manipulating processes}

In this part we are mainly interested in manipulating process priorities and scheduling behavior. 
The POSIX calls and standards are investigated to verify possibilities.

\subsection{PID namespaces}

Before considering option of sharing PID space with host, see if we can access from a privileged container nonetheless the namespace isolation. 
Posix defines functions ioctrl\_ns to determine the parent namespace of the actual one. can help getting the inode of a parent namespace and read information. 
if pids can also be read is a matter of investigation. maybe mount as \/procext?

what information can be read out from the pid is still to be investigated.

Manuals say that a parent can read child namespaces but not vice-versa. All enquiries of pared pid in fact once reached pid 1 (must not be 1 for a container) end up with a 0 response.

\subsection{PID information}
\label{sub:pidinf}

While in UNIX the PID table and information is part of the kernel memory, in linux the only way to access the process information is by parsing virtual files. 
If the orchestrator has to run on both systems, the PID retrieval must thus be implemented twice. Once via /proc pipe readout and once via sysctrl calls to read kernel memory.

It is highly likely that the same is true for the other resources, such as memory or connectivity. 

An example code has been tested which gives the PID's of all matching process names. 
It might therefore be possible to poll once and verify cyclically for unbound containers. 

A hook-like structure might be more convenient. Such modification would require a kernel change and is therefore considered only in a second moment.

\subsection{Scheduling of processes}

As default there is only limited access to the scheduling activities of a process.
In the POSIX documentation we find the following functions:

\begin{itemize}
	\item \textbf{sched\_get\_priority\_max(int)}
		gets the max priority of the specified scheduling policy. On Linux, it is 0 for SCHED\_OTHER and 1 for everything else. 
	
	\item \textbf{sched\_get\_priority\_min(int)}
		gets the min priority of the specified scheduling policy. On Linux, it is 0 for SCHED\_OTHER and 99 for everything else. 
		
	\item \textbf{sched\_getparam(pid\_t, struct sched\_param *)}
		gets the scheduling parameters of a specified process ID
	
	\item \textbf{sched\_getscheduler(pid\_t)}
		gets the set scheduling policy for a PID
	
	\item \textbf{sched\_rr\_get\_interval(pid\_t, struct timespec *)}
		gets the length of the quantum used when using the round robin scheduling approach for realtime.
		With a Linux kernel, the round robin time slice is always 150 microseconds, and pid need not even be a real pid. At least that is what the manuals say. Interrestingly a test has shown that there are also 8000 or 16000 $\mu s$ sometimes returned when querying the value.
	
	\item \textbf{sched\_setparam(pid\_t, const struct sched\_param *)}
		sets the parameters for a specified process ID
	
	\item \textbf{sched\_setscheduler(pid\_t, int, const struct sched\_param *)}
		sets the scheduling policy for a PID
	
	\item \textbf{sched\_yield(void)}
		return the control to the scheduler (leave the execution state).
\end{itemize}

In addition, if the scheduling is set to traditional, i.e. SCHED\_OTHER, the niceness value for the complete fair scheduler can be adjusted with additional functions. 

POSIX as said, implements only three scheduling policies.
Linux in addition has now:

\begin{verbatim}
#define SCHED\_BATCH		3
/* SCHED\_ISO: reserved but not implemented yet */
#define SCHED\_IDLE		5
#define SCHED\_DEADLINE		6
\end{verbatim}


In addition, scheduling attributes are now extended as:

\begin{verbatim}
struct sched\_attr {
	__u32 size;
	
	__u32 sched\_policy;
	__u64 sched\_flags;
	
	/* SCHED\_NORMAL, SCHED\_BATCH */
	__s32 sched\_nice;
	
	/* SCHED\_FIFO, SCHED\_RR */
	__u32 sched_priority;
	
	/* SCHED\_DEADLINE */
	__u64 sched\_runtime;
	__u64 sched\_deadline;
	__u64 sched\_period;
};
\end{verbatim}

and might be read and written as follows:


\begin{verbatim}
int sched_setattr(pid_t pid, struct sched_attr *attr,
	unsigned int flags);

int sched_getattr(pid_t pid, struct sched_attr *attr,
	unsigned int size, unsigned int flags);
\end{verbatim}

This structure is in addition to the original sched\_param which has been kept for standardization and backwards compatibility issues.

The commented scheduling mode in the list, i.e. SCHED\_ISO, is a scheduler intended for isochronous (burst-like) tasks and has not been implemented yet. 
The brainfuck scheduler (BFS) developed by Con Kolivas is anltered version witch actually supports the ISO scheduling mode, with priority between RT and Normal/Other tasks.
For further details see "A complete guide to Linux process scheduling"  by Nikita Ishkov.


\subsection{Other considerations}

During the exploration of the namespace and pid function, some features to be implemented in future where discovered. 
The PID 1 inside the container is parent of all the namespace. If it dies, all the children are orphaned and will be killed. As parent, it is also target of sigs without implicit binding, thus it must manually handle incoming signals such as sig\_int.
The userspace in the container can be mapped. To avoid root as well as other accesses from a container, a proper map should be set up and incorporated in all the containers at load.

\section{Test implementation}

The orchestrator will have to interact with the scheduler while monitoring the tasks. 
Ideally, the interaction is mutual. Unfortunately, no hint has been found suggesting that there is a way to ``register'' to the scheduler to get scheduling and process updates. 
Thus, apart from the system calls for getting and setting a process's scheduling attributes, there is no direct communication with the kernel. 
This means that the PIDs of all the processes must be queried manually, cyclically, considering time trends and thus the orchestrator must keep PID history. 

\subsection{PID search}

%% how
In a first implementation test, we verify therefore the poll quality and speed of pid queries.
As described in Section \ref{sub:pidinf}, there are two ways of polling the prcess table. 
In our testing environment we use Linux, and are therefore running for a virtual filesystems parsing. 
To ease the parsing, we can use the integrated tool ``pidof'' via a pipe opened through the call of \texttt{popen}.
\texttt{popen} is a POSIX standard call that opens a one-way pipe to indicated  purposely process called via shell.

%% in the programm
As soon as the orchestrator is up and running, it scans for target processes which might be  defined in a configuration file (\textit{cmdfile}).
The PID list is parsed and verified. 
The whole process takes a fraction of a ms and does not put load on the {CPU}. With unlimited loop the {CPU}-load is below 3\%.

%% Consequences and results>>
An option to optimize process verification might be that the environment controlling the containers informs the orchestrator about containers entering or leaving the scheduler.
This way, an orchestrator does not have to scan for new PID all the time.
Kubernetes, for example, foresees the use of postStart and preStop handlers when installing a pod. 
The handlers can be specified in the yaml configuration file of the POD for each container. A Typical use for this might be the shutting down or preparation for a service such as a web server. 
In our case we could use it to signal a process start or stop.
More details about this configuration can be \href{{https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/}}{found here}.
The Docker API on the other hand does not implement a pre- or post execution handler for container start or stop. 
Only the container configuration itself could contain a run command as part of the container to be executed upon startup. This might be also a standard configuration setting, signaling the orchestrator the presence of a new container process.
Anyway, this will be a feature to be implemented in a second moment.

The test development is stored in git under {src/testPosix/thread.c}.

\subsection{PID list}

%% how
Once the PIDs have been acquired, the orchestrator has to maintain a list of active processes. 
For this purpose, and in order to match PIDs with scheduling information, a dynamic memory structure may be used.
In order to store the information, the sorted resulting PID number array is sequentially used to fill a dynamic structure with scheduling data. 
Cyclically, the memory structure will be compared with the updated PIDs. New processes will be inserted in orded in the structure, removed PIDs will be dropped.
The actual type of dynamic data structure is irrelevant. Possible structures are linked lists, double linked lists, as well as sorted trees of any kind.

%% In the program
To test an implementation, a simple linked list has been implemented as a separate source file {src/testPosix/pidlist.c}.
The test program structure has been rewritten. Now two threads are launched to keep track of the running processes. 

Thread 1 will keep track of pids, add and remove list elements. The resulting PID array of a periodic scan is compared to the list's content.
Insertion and deletion signals the presence of a new or removed process to the other thread.
Thread 2, implemented in a second step, will take care of the distribution of resources among the listed PIDs. 

%% Considerations.
Thread 1 implementation works fluently. For the final implementation, Kernel list based structures should be considered. 
The implementation uses predefined macros for add and delete in the list. Differently from the managed list, this implementation does not cover the memory management of the structure. Memory allocation and freeing must still be done by the programmer.

\subsection{PID scheduling}
 
%% how
As a final step for the basic PID scheduling, we gather the information of a target process and set the new attributes. 
Resources, initially only {CPU}-affinity, are distributed according to configured settings, i.e. max values for resource occupation. 
This is for example a 80\% boundary for each computation unit ({CPU}). 
The daemon and other system tasks should be mapped to separate resources. Even though real-time tasks have higher priority, a separate cpu might be needed to keep enough boundary for new entries and the system responsive.

%% In the programm
A CPU has a standard cyclic computation monitoring unit of 1 ms, separating it into 1000000 ticks. The different runtimes, deadlines and periods of the periodic tasks will be used to find a common denominator on a 1ms basis. 
In the end, e.g. 80\% of {CPU} are filled cyclically. 
The different distribution strategies, i.e. round robin etc., might be implemented in the final product.

%% Considerations
Thread 2 with be responsible for this task. Cyclically, and in a second moment by trigger, the new PIDs are configured to associate with specific resources.
As this might introduce some resource peak, the reallocation must happen as soon as possible. 
The new process entry might use any of the resouces and thus add some unwanted peak load. 
If possible, the daemon and consequently the new created container processes should be bound to a reserved {CPU}, where all the system tasks are also allocated.

\subsubitem{Thread communication}

%% How
The communication between the running threads can be performed in different ways:

\begin{enumerate}
	\item we might use the usual IPC, as it is done between processes via
	\begin{enumerate}
		\item pipe - a connection between in and out, therefore not easily doable as the threads by default share the same stdin and stdout;
		\item signals - such as \textit{INT} or \textit{HUP} which might be sent between processes, but hardly doable on the same process but different threads. The process would need to signal itself;
		\item sockets - might be used as a medium where both threads access externally to this resource and exchange information;
	\end{enumerate}
	\item shared memory - probably the easiest type. The advantage of threads is that they 
	share memory. Thus the only additional feature we need are locks/semaphores. Then, data can be exchanged in shared locations or FIFO buffers.
\end{enumerate}
The easiest approach therefore is to use shared variables and a semaphore/mutex.

%% In the program
In our test implementation we add a pthread\_mutex\_t to be acquired before every access to the PID list.
This way it is possible to instantiate a simple mechanism of intrinsic communication, without having to specify any additional data and protocol.
The program changes are minimal and thus the code remains as readable as before.

%% Considerations
The two threads can manage the list independently as before. On every execution the actual thread has exclusive access to the list.
This way, thread one can drop any removed item simply from the list and add new PIDs once discovered. 
Thread two has to scan the PID list anyway.
If new empty items are found, the settings are populated and resources allocated and scheduled.
The important part here is to assure that the critical section and the new task default resources are not part of the managed spectrum.
Any new entry has to be reallocated as soon as possible, but at the same time, there must be found a way to allocate new containers by default to specific resources.

\subsection{Affinity selection}

%% How
Affinity selection can be done via the commands \texttt{sched\_setaffinity} and \texttt{sched\_getaffinity}.
A variety of auxiliary commands are available. 
The macro commands starting with \texttt{CPU\_*} are used to create and modify CPU-Set masks.
Those masks are then needed to change a process's affinity.

%% In the program
In the program the new entries found by thread two will be checked for affinity and resources.
Once the task information has been gathered, the updated values will be set according to the actual configuration.
The distribution and cap of resources might be defined as round robin or alike.
During this phase, thread two will also read actual values and monitor the execution cap of tasks.

%% Considerations
This is the last active section of the test implementation and probably the most complicated as well.
The ideal resource management is hard to guarantee.
The thread has to calculate utilization values and utilization limits, things known from real time scheduling theory, multiple times a second. 
If we do not consider interdependence of the threads, the scheduling algorithm might be simplified to operate on multiple single core units with dedicated memory and I/O.
If the tasks are instead depending on each other, more complex and sophisticated algorithms are needed.
Such algorithms must surely be reevaluated for the dynamic scheduling version.

\subsection{Parameters and configuration}

%% How
Parameter configuration can be done in multiple ways. The two major options taken into consideration are parameter file and command line parameters.
The latter might work for a test phase, but might get to be a burden once the system and configurable parameters grow in size.
A combination of both might be the ideal solution.

%% In the program
For some first tests, command line parameters will be used to set thresholds and limits. Those will later be moved into a configuration file.
The parameters include Ulimit, CPU masks of reserved computing units, memory maps and I/O resources that might be configured. 
For the implementation, the posix getopt parsing function will be used.
To parse the configuration file, a pre-defined library will be used where possible.

%% Considerations
When working with strings and buffers, such as configuration files, particular attention must be given to the possibility of buffer overflows and alike.
Finally, the combination of configuration file containing all process details and the command arguments, needed for example to select configuration file and set verbosity, might be the best option.

\section{RT-app}

During the tests, rt-app will be used as a test application, simulating real-time containers. 
To monitor the app, the interaction with Icinga is foreseen.
To gather proper information, the output of the application should be parsed and sent to the monitoring server.
A plugin has to be written to interact with the Icinga daemon.
Based on an existing plugin source code, a template for the new plugin has been created. 
The instructions for a \href{{https://nagios-plugins.org/doc/guidelines.html#DEVREQUIREMENTS}}{Nagions plugin} are used to create the proper plugin output.


\subsection{Configuration}

%% How
The configuration of RT-app is done via a JSON file. The file specifies the amount, type and duration of the computing simulation tasks.

%% In the program
For the purpose of out project, each container will have only one task. 
Thus, the configuration will contain only one entry for thread and a global configuration.
Times defined in the configuration are in $\mu s$.

%% Considerations
The configuration sample can be found in the git repository, inside the folder \texttt{prj/test\_cont}.

\subsection{Logging}

%% How
RT-app includes a logging function to keep track of all tasks activity during execution. The logging itself writes to a file without rotation or buffers.
This thus does not allow to use the default logging function for continuous monitoring purposes.
If a ring-buffer is set in the configuration settings, the buffer is written to file only once the test is finished or interrupted. 
Thus, an adaptation of the logging function might be needed to allow readout of the task's performance.
The source code is available and written in C. Changes should therefore be no major problem.

%% In the program
Some minor changes to the logging function have been successfully tested. Insertion of the ring-buffer dump every time it's capacity has been reached and overwriting of the log-file works as expected.
Issues that might be encountered are the high load to disk I/O if a small disks buffer size forces to write to file, and consequently induces delays.

%% Considerations
An option to consider might be the writing to the stdout and piping the process to the Icinga plugin. 


\subsection{Icinga plugin}

%% How
Icinga plugin running in paralel to the orchestrator. We need data about the tasks and the network performance. In the end we dont watn to create too much overhead for the system, therefore it would be ideal if the orchestratior might be able to exchng the task data obtained from the system scheduler with the plugin.
Other data that can be read is the network throughput. although it might influence the performance , in particular if we want to implement time sensitive networks.
The overhead of the virtual internal network could push on the actual performance. we should check if there is a way of reading io of the network withouth having to create a virtual subnet.
Also possible might be to read disk I/o of a container. even though it could be that it is not necessary. 
IS there an icinga plugin made for docker containers already available that can be adapted?



%% In the program


%% Considerations


% Time syncronous network (TSN) maybe necessary

Heuristic bound, wc has to be satisfied
do on the go within boundaries, otherwise is undecideable
need to get the bounds
Scheduling algorithm with known bounds
rendezvous mechanism to go 
way of achieving hard 
-> constraints into a cost function


Sophisticate -> eplsylon out of bound is added cost -> calculate alg

Container
Crap -> container - run test

C -> binary code can be linked to the final binary to increase the efficiency of the whole thing

Reduce the load of the operating system -> quasi static system, decision, compile policy together with the thing.

paper alberto -> scheduling integer linear,
-> forward 
ballarin, 

\bibliography{IEEEabrv,bibliography}

\end{document}
